{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Data Labeling</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 Outline\n",
    "\n",
    "- Data Labelling\n",
    "    - types\n",
    "    - challenges\n",
    "    \n",
    "- Data labelling at scale using human workforces\n",
    "- Deploying data labelling best practices\n",
    "\n",
    "- Automatic data labelling & active learning\n",
    "    - data labelling at scale\n",
    "    \n",
    "- Human-in-loop  pipeline\n",
    "    - review machine learning predictions\n",
    "    \n",
    "- Human & AI collaboration\n",
    "    - Data labelling at scale\n",
    "        - tool: Amazon SageMaker GroundTruth\n",
    "    - Human review of model prediction\n",
    "        - tool: Amazon Augmented AI (Amazon A2I) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labeling\n",
    "\n",
    "- Successful mmodels are built on hight quality data\n",
    "- collecting and labelling data require time and energy\n",
    "\n",
    "## Data Scientiest time\n",
    "- <img src='./pics/ds time.png'>\n",
    "\n",
    "## What is data labeling?\n",
    "- identify the raw data and adding one or more meaningful labels\n",
    "- labels provide context for the machine learning models to learn from (supervised learning)\n",
    "- correctly labelled dataset known as <b>\"groud truth\"</b>\n",
    "\n",
    "## Common types of data labelling\n",
    "- image data\n",
    "    - bouding box\n",
    "        - find the birds in the image and draw a bounding box\n",
    "    - single label classification\n",
    "        - given image is a dog or cat\n",
    "    - multi label classification\n",
    "        - what are the objects present in the image?\n",
    "    - Semantic Segmentation\n",
    "        - find the pixcels constitute an image\n",
    "        \n",
    "    - <img src='./pics/image data.png'>\n",
    "    \n",
    "- Video data\n",
    "    - Video classification\n",
    "    - Video object detection\n",
    "        - bounding box: bounding box around the image\n",
    "        - polygon: polygon over the object\n",
    "        - polylines\n",
    "        - key points\n",
    "        - track the object\n",
    "            - insted of looking frame by frame you track the movement of an object in the video frames\n",
    "    - <img src='./pics/video data.png'>\n",
    "    \n",
    "- Text Data\n",
    "    - Singel label classification\n",
    "        - find sentiment of the text (positive/negative)\n",
    "    - multi-label classification\n",
    "        - classify the text as postive and inspiring\n",
    "    - Named Enitty Recognition\n",
    "        - identify the places and names in the text\n",
    "    - Optical character recognition\n",
    "    \n",
    "    - <img src='./pics/text data.png'>\n",
    "\n",
    "## Challenges\n",
    "- Massive scale: 10k image to train a image recognition model\n",
    "- High accuracy: the labelled data should be accurate, otherwise system will learn from inaccurate data and predict in accuratly\n",
    "- Data labelling is time consuming\n",
    "\n",
    "## Solution\n",
    "- human labelers + managed services\n",
    "    - additional human workforce\n",
    "    - automated data labelling caipability\n",
    "    - additional features for data lablers to increase the labeling quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labeling with Amazon SageMaker Ground Truth\n",
    "\n",
    "- setup a data labelling task with few steps\n",
    "- labelled the data stored in S3\n",
    "    - automated labelling\n",
    "    - human labelling\n",
    "    - crowd sourced amazon mechanical turk force\n",
    "\n",
    "- <img src='./pics/AWS GroundTruth.png'>\n",
    "\n",
    "## How it works\n",
    "- a pointer to the s3 location\n",
    "- define task\n",
    "    - provide relevant labelling instructions\n",
    "    \n",
    "- GroundTruth gives templates to make the task easy\n",
    "    - we can create ourown templates\n",
    "    \n",
    "- as last step you create a human workforce\n",
    "    - public crowd source workforce\n",
    "    - third party labeling service provider\n",
    "    - yourown coworkers (as third party work force)\n",
    "    \n",
    "- once the process is complete you can find the labelled data in S3\n",
    "\n",
    "## Data Labelling Job\n",
    "- Setup Input Data\n",
    "- Select Labelling Task\n",
    "- Select Human Workforce\n",
    "- Create Task UI\n",
    "\n",
    "### Setup Input Data\n",
    "\n",
    "#### Automated Data Setup\n",
    "- data should be in S3\n",
    "- Automated Setup you only need to provide the location, the GroundTruth identify the dataset and connect to the labelling job\n",
    "    - input manifest file (the file GroundTruth create that identifies the data)\n",
    "    \n",
    "#### Manual Data Setup\n",
    "- provide the S3 location of a file (an input manifest file) that identifies the data object you want to label\n",
    "- the manifest file point to a location or to the data itself\n",
    "- <img src='./pics/input manifest file.png'>\n",
    "\n",
    "### Select Labeling Task\n",
    "- Labeling task may be of\n",
    "    - Image Data\n",
    "        - single label\n",
    "        - multi label\n",
    "        - Bounding box\n",
    "        - semantic segmentation\n",
    "        - Label varification\n",
    "    - Video Data\n",
    "        - Video Clip Classification\n",
    "        - Video Object Detection/Tracking\n",
    "            - Bounding Box\n",
    "            - Polygon\n",
    "            - Polyline\n",
    "            - Key Point\n",
    "    - Text Data\n",
    "        - Single Label Classification\n",
    "        - Multi Label Classification\n",
    "        - Named Entitiy Recognition\n",
    "    - Custom\n",
    "    \n",
    "- Creating a Custom Labeling Task\n",
    "- <img src='./pics/custom labeling task.png'>\n",
    "\n",
    "### Select the Human Workforce\n",
    "- Work force of your choise\n",
    "    - Amazon Mechanical Turk\n",
    "        - 500K contractors\n",
    "    - Private\n",
    "        - labeling require domain knowledge: use employees or co-workers\n",
    "        - you can restirct worker access to tasks to allowable IP addresses\n",
    "    - Vendor\n",
    "\n",
    "### Steps (Private Task)\n",
    "- Setup Private Workforce (UI)\n",
    "- <img src='./pics/data label private workforce.png'>\n",
    "- create a private team using Amazon Cognito / OpenID Connect\n",
    "- <img src='./pics/create workforce.png'>\n",
    "- now you can invite workers through email or importing from amazon cognito user group\n",
    "- <img src='./pics/inviting workforce.png'>\n",
    "- Create Task UI\n",
    "    - you can use a built-in template or define a custom UI\n",
    "    - Combination of HTML, CSS, JavaScript can be used to create Custom UI, or to customize the selected one\n",
    "    \n",
    "    - Sample Task UI for Text Classification\n",
    "    - <img src='./pics/Task UI Template.png'>\n",
    "    - customization instruction also given\n",
    "    - <img src='./pics/Classification page.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Labeling Best Practices\n",
    "\n",
    "- Provide clear instructions\n",
    "    - provide examples of good and bad annotations\n",
    "        - good and bad annotation\n",
    "        - <img src = './pics/good and bad annotation.png'>        \n",
    "    - show only relevant labels\n",
    "    - use multiple workers per task (can specify how many worker should see a data)\n",
    "        \n",
    "- consolidate annotations to imporve label quality\n",
    "    - there should be a way to consolidate annotation (if you bring the work to more workers)\n",
    "    - <img src = './pics/consolidating label.png'>\n",
    "    - GroundTruth provides a annotation consolidation function for each of the built-in labeling work\n",
    "    - you can also define your function\n",
    "    \n",
    "- varify and adjust labels\n",
    "    - you should do a Quality audit on the label\n",
    "    - fist label the data\n",
    "    - then use a QC team to check the quality of labeling\n",
    "    - you can reduce the size of data to reduce the time taken\n",
    "    - the new labels will be appended on the initial one, so you can find the key performance indicators (KPIs)\n",
    "    - in step 3 you can do a random sampling and find the errors on the sampled data\n",
    "    - <img src = './pics/quality check on labels.png'>\n",
    "    \n",
    "- Use automated data labeling on large datasets (Active Learning)\n",
    "    - note (active learning: is a machine learning technique that identifies the data that should labeled by human)\n",
    "    - automated data labeling is optional\n",
    "    - when you choose this a part of the data is labeled using active learning\n",
    "    - <img src = './pics/automatic data labeling.png'>\n",
    "    - the minimum number of object allowed for automatic data labeling is 1250 but it is better if the number is 5000\n",
    "    \n",
    "- Re-use prior labeling jobs to create hierarchical labels\n",
    "    - eg fist use a label job to categorize cats and dogs then use the dog labeled data to label diff breeds of dogs\n",
    "    - <img src = './pics/re-use prior labeling.png'>\n",
    "    - the output of the second job will be an augmented manifest file (the output contain both the labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Human-in-the-loop Pipelines</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-in-the-loop Pipelines\n",
    "\n",
    "- ML + Human to get a required level of precision\n",
    "- use when\n",
    "    - model unable to predict with an expected confidence level\n",
    "    - audit the prediction\n",
    "    \n",
    "    - <img src='./pics/human-in-the-loop.png'>\n",
    "    \n",
    "    - another usescase is form extraction\n",
    "    - <img src='./pics/form extraction.png'>\n",
    "    - form extraction requre human intervaention because of poor quality scan or because of poor handwriting\n",
    "    \n",
    "## Steps to implement human review of model prediction\n",
    "- <img src='./pics/human pipeline steps.png'>\n",
    "- the thrshold of the human review based on the use case\n",
    "- insted of a threshold you can do a random sampling for human auditing\n",
    "\n",
    "## Challenges\n",
    "- Need to cordinatesML Scientiest, engineering, and operations teams\n",
    "- Need to manage large number of reviews\n",
    "- Need to write custome software to manage review tasks\n",
    "- Difficult to achieve high review accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human-in-the-loop Pipelines with Amazon Augmented AI (Amazon A2I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
